{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nG97D9h7rgGx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDhRVO41sM-d",
        "outputId": "77e133b5-53b7-4073-b0ec-3e28722909c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  shakespeare_model.h5  shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"shakespeare.txt\", \"r\").read()"
      ],
      "metadata": {
        "id": "8dUGQiBisFz0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text = re.sub(r'\\d', '', text.replace('\\n', ' ').replace('\\t', ' ').replace('  ', ''))"
      ],
      "metadata": {
        "id": "z9i3_ITbsT0Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text[0:56]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uGqOt9qgsUwv",
        "outputId": "eb0991d4-8991-44a1-ec3d-2b4053318a24"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is the th Etext file presented by Project Gutenberg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(cleaned_text))"
      ],
      "metadata": {
        "id": "Q07mizcewE2I"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(characters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roYurl7JxF89",
        "outputId": "c803c48c-9fde-4f2c-de1b-47d7b9d53c36"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_index = {char:index for index, char in enumerate(characters)}"
      ],
      "metadata": {
        "id": "R26e6_GixMnH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char = {index:char for index,char in enumerate(characters)}"
      ],
      "metadata": {
        "id": "ZMpG23gXxHRL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 40"
      ],
      "metadata": {
        "id": "s5fhDg5Zxgou"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step_size = 5"
      ],
      "metadata": {
        "id": "g67yJ7w4xn8J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "next_characters = []"
      ],
      "metadata": {
        "id": "05SBGN0C47Gn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(cleaned_text)-seq_length, step_size):\n",
        "  sentences.append(cleaned_text[i:i+seq_length])\n",
        "  next_characters.append(cleaned_text[i+seq_length])"
      ],
      "metadata": {
        "id": "KXuGD_Ytxs7R"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences),seq_length,len(characters)),dtype = bool)"
      ],
      "metadata": {
        "id": "z4jgerbW6XNU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.zeros((len(sentences),len(characters)),dtype = bool)"
      ],
      "metadata": {
        "id": "URVyoyoTA_tA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sentence in enumerate(sentences):\n",
        "  for t, character in enumerate(sentence):\n",
        "    x[i, t, char_to_index[character]] = 1\n",
        "  y[i,char_to_index[next_characters[i]]] = 1"
      ],
      "metadata": {
        "id": "m6N6ty28Gv86"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmrrxcqM0JlQ",
        "outputId": "d383c1d0-4683-44d1-954c-614245d1cd8a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(985343, 40, 80)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-dhLBOk0SLc",
        "outputId": "ba87e105-f388-4627-bab1-9508ff61568a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(985343, 80)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "tjQOWrrAIA7J"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(LSTM(128, input_shape = (seq_length, len(characters))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzpUm8kuSkRI",
        "outputId": "82e1cdc9-1235-4e0b-94ef-8eb111e1657f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(len(characters)))"
      ],
      "metadata": {
        "id": "nRjIIpUueI1u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "7hpbC3z1eROf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(learning_rate = 0.01))"
      ],
      "metadata": {
        "id": "KbXcpzgLe3ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,batch_size = 256, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_Rt1028e-ln",
        "outputId": "8bfdc140-481e-4527-ffb2-fe7ec68dc7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3849/3849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 200ms/step - loss: 2.1399\n",
            "Epoch 2/5\n",
            "\u001b[1m3849/3849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 201ms/step - loss: 1.6184\n",
            "Epoch 3/5\n",
            "\u001b[1m3849/3849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 200ms/step - loss: 1.5465\n",
            "Epoch 4/5\n",
            "\u001b[1m3849/3849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 200ms/step - loss: 1.5264\n",
            "Epoch 5/5\n",
            "\u001b[1m3849/3849\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 200ms/step - loss: 1.4957\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78393a0f6140>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('shakespeare_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ae8-jufFYJ",
        "outputId": "0bc40cb8-1533-43e5-88b4-f33b74e0ff1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('shakespeare_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaENb_R2xP7B",
        "outputId": "0a51e1cf-628c-48d5-d124-8e86242136d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds,temperature = 1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds)/temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds/np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1,preds,1)\n",
        "  return np.argmax(probas)"
      ],
      "metadata": {
        "id": "JnSMdI1jxW1V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "  start_index = random.randint(0,len(cleaned_text)-seq_length-1)\n",
        "  generated = ''\n",
        "  sentence = cleaned_text[start_index:start_index+seq_length]\n",
        "  generated += sentence\n",
        "  print(generated)\n",
        "  for i in range(length):\n",
        "    x = np.zeros((1,seq_length,len(characters)))\n",
        "    for t, character in enumerate(sentence):\n",
        "      x[0,t,char_to_index[character]] = 1\n",
        "    predictions = model.predict(x,verbose = 0)[0]\n",
        "    next_index = sample(predictions,temperature)\n",
        "    next_character = index_to_char[next_index]\n",
        "    generated += next_character\n",
        "    sentence = sentence[1:] + next_character\n",
        "  return generated"
      ],
      "metadata": {
        "id": "OBpPCjMzPiuW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(120,0.2))"
      ],
      "metadata": {
        "id": "lKYcPv-OnPhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8370e044-ba2a-4ade-8b49-6d645b91d6f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r lead me, like a firebrand, in the dark\n",
            "r lead me, like a firebrand, in the dark of the fear. If you say the world and the treather to the present of the tent. If you say thee to the man in his part and the world and bear the heart, And the heart of the world to the truth of the companion of the truth, That the world the house o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uO14RqGGnXyn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
